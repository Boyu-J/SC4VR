{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb18004e-bc94-41b1-9edd-479608dd5116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'path/to/video_folder/' # video_folder contains video.mp4\n",
    "from collections import Counter\n",
    "from torchvision.io.video import read_video\n",
    "from torchvision.models.video import r3d_18 , R3D_18_Weights\n",
    "import cv2\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "from torchlars import LARS\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import av\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score, silhouette_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, average_precision_score, balanced_accuracy_score\n",
    "\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ce2535-ce47-4c08-8e53-164fbb3a1d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed value\n",
    "seed = 7\n",
    "set_seed(seed)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34aeff9d-10c6-4dc3-b0ad-2971f386ab4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 cuda:1\n"
     ]
    }
   ],
   "source": [
    "device0 = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device1 = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device0, device1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc26b0ce-1518-4dd8-9ea3-5f6e7ec768a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default CUDA device to GPU 0 (for example)\n",
    "torch.cuda.set_device(0)  # Change the index to the desired GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40dd394-cd4f-4377-a997-00a292c2a2fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# load video encoder: Video ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc52f7b7-7603-4a50-991e-45d2ea1253c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the weights \n",
    "weights = R3D_18_Weights.DEFAULT\n",
    "\n",
    "encoder_anchor = r3d_18()\n",
    "\n",
    "# remove the classification head. Keep the backbone\n",
    "encoder_anchor = torch.nn.Sequential(*(list(encoder_anchor.children())[:-1]))\n",
    "\n",
    "# require gradient for training\n",
    "for param in encoder_anchor.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c0355-fe8b-4ec6-ba0e-2cce3faeeddf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a3c4d-2082-4038-a4b4-d323699f3970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv('Example_video_label.csv') # change to your label file\n",
    "\n",
    "file_names = os.listdir(path)\n",
    "len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63f106c6-dbb4-4fa6-b647-53dbe9ad72a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label = events['EVENTSEVERITY1'].tolist()\n",
    "y = {'Crash': 2, 'Baseline': 0, 'Near-Crash': 1}\n",
    "\n",
    "# Convert character elements to integers\n",
    "label = [y[char] for char in label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "490ad57f-ff8c-49e7-a7be-901cd9898790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the inference transforms\n",
    "weights = R3D_18_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "\n",
    "def process_video(file):\n",
    "    vid, _, _ = read_video(path + file, output_format=\"TCHW\", pts_unit='sec')\n",
    "    return preprocess(vid[:77]) # extract first 77 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51581183-53ca-4eae-a5ad-a0442eba91fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_files, temp_files, train_labels, temp_labels = train_test_split(file_names, label, test_size=0.3, \n",
    "                                                                      random_state=7)\n",
    "\n",
    "val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.667, \n",
    "                                                                  random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0fa8887-e451-4c31-8267-8e76cef664f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split training set for DataLoader\n",
    "num_splits = 4\n",
    "train_files_split = [train_files[i::num_splits] for i in range(num_splits)]\n",
    "train_labels_split = [train_labels[i::num_splits] for i in range(num_splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a54c98d-478b-4381-abfb-6b425886693b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load validation sets\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    X_val = list(executor.map(process_video, val_files))\n",
    "\n",
    "X_val = torch.stack(X_val)#.to(device1)\n",
    "Y_val = torch.as_tensor(val_labels)#.to(device1)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "val_dataset = TensorDataset(X_val, Y_val)\n",
    "del X_val, Y_val\n",
    "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False)  # Adjust batch_size as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaffcc72-b1ff-4583-b2df-7c5111fef858",
   "metadata": {
    "tags": []
   },
   "source": [
    "# loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed215ce7-9faf-4380-b2ad-1518cfb0a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=10.0, base_temperature=10.0): # temperature can be adjusted\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temperature = nn.Parameter(torch.tensor(temperature))# Make temperature learnable\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        features = torch.nn.functional.normalize(features, p=2, dim=1)\n",
    "        features = features.unsqueeze(1)\n",
    "        batch_size = features.shape[0]\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(device1)\n",
    "\n",
    "        contrast_count = features.shape[1]\n",
    "        # Unbinds the features tensor along dimension 1 and concatenates the resulting tensors along dimension 0.\n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "\n",
    "        anchor_feature = contrast_feature\n",
    "        anchor_count = contrast_count\n",
    "\n",
    "        # compute logits\n",
    "        anchor_dot_contrast = torch.div(torch.matmul(anchor_feature, contrast_feature.T), self.temperature)\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        # tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        # mask-out self-contrast cases\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device1), \n",
    "            0\n",
    "        )\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "\n",
    "        # compute mean of log-likelihood over positive\n",
    "        mask_pos_pairs = mask.sum(1)\n",
    "        mask_pos_pairs = torch.where(mask_pos_pairs < 1e-6, 1, mask_pos_pairs)\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask_pos_pairs\n",
    "\n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        loss = loss.view(anchor_count, batch_size).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6e072a-063c-4d09-a8d4-2c4957de05dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# train encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adcfa3f-57e6-43a2-8fb4-a09d19e018d0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "encoder_anchor = encoder_anchor.to(device1)\n",
    "\n",
    "encoder_anchor.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "705c9533-dc9f-4f02-b89e-fc4f4eed2b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "ContrastLoss = ContrastiveLoss(temperature=10.0, base_temperature=10.0)\n",
    "optimizer_encoder = optim.Adam(params = encoder_anchor.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa7daa9-2177-45c9-aff0-f9e923362bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_splits = 4\n",
    "train_datasets = []\n",
    "\n",
    "def process_split(split):\n",
    "    # load preprocessed video file\n",
    "    X_split = torch.load(f'Processed_video_r3d18/train/X_train_frame77_{split}.pt', weights_only=True)\n",
    "    Y_split = torch.load(f'Processed_video_r3d18/train/Y_train_frame77_{split}.pt', weights_only=True)\n",
    "    return X_split, Y_split\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    results = executor.map(process_split, range(num_splits))\n",
    "\n",
    "for X_split, Y_split in results:\n",
    "    train_datasets.append(TensorDataset(X_split, Y_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59238a80-2c23-47ea-a61a-b7840fd5018f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BatchSize = 64 \n",
    "train_loaders = []\n",
    "\n",
    "for split in range(num_splits):\n",
    "    train_loaders.append(DataLoader(dataset=train_datasets[split], batch_size=BatchSize, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a279b-6162-455c-96d8-0fc4f10f23a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### start training ####\n",
    "best_val_ss = 0.0\n",
    "best_val_loss = 99999.9 \n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer_encoder, T_max=num_epochs, eta_min=0)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    results_file = open('results_encoder_ScratchLearn.txt', 'a') # create a txt file for saving the training records\n",
    "    running_loss = 0\n",
    "    for split in range(num_splits):\n",
    "        for data, targets in train_loaders[split]:\n",
    "            optimizer_encoder.zero_grad()\n",
    "            data = data.to(device1)\n",
    "            targets = targets.to(device1)\n",
    "\n",
    "            h = encoder_anchor(data)\n",
    "            h = h.view(h.size(0), -1)\n",
    "            contrastive_loss = ContrastLoss(h, targets)\n",
    "            running_loss += contrastive_loss\n",
    "\n",
    "            contrastive_loss.backward()\n",
    "            optimizer_encoder.step()\n",
    "        \n",
    "        del data, targets\n",
    "\n",
    "    # Validation phase\n",
    "    ss_result = []\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_Y in val_loader:\n",
    "            batch_X = batch_X.to(device1)\n",
    "            batch_Y = batch_Y.to(device1)\n",
    "\n",
    "            h_val = encoder_anchor(batch_X)\n",
    "            h_val = h_val.view(h_val.size(0), -1)\n",
    "            val_loss += ContrastLoss(h_val, batch_Y)\n",
    "            ss = silhouette_score(h_val.cpu().numpy(), batch_Y.cpu().numpy())\n",
    "            ss_result.append(ss)\n",
    "\n",
    "\n",
    "    mean_ss = sum(ss_result) / len(ss_result)\n",
    "    results_file.write(f'Epoch [{epoch+1}/{num_epochs}], Contrastive Loss: {running_loss.item():.5f}, Val loss: {val_loss:.5f}, Val Silht score: {mean_ss:.5f}\\n')\n",
    "    \n",
    "    if mean_ss > best_val_ss:\n",
    "        best_val_ss = mean_ss\n",
    "        \n",
    "        torch.save(encoder_anchor.state_dict(), 'best_encoder_ScratchLearn.pth') # save the best video encoder\n",
    "        results_file.write(f'New best encoder saved with Silht scores: {best_val_ss}\\n')\n",
    "\n",
    "    del batch_X, batch_Y\n",
    "    torch.cuda.empty_cache()\n",
    "    results_file.close()\n",
    "    scheduler.step()\n",
    "    \n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5fe13ea-8ad3-4194-98ea-6bec43f01732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d5595-6f42-4dbe-9e3e-374e24e2df9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# train classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c4186-8121-413e-be3a-b8a26b095106",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = R3D_18_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "trained_encoder = r3d_18()\n",
    "fc_layer = torch.nn.Linear(trained_encoder.fc.in_features, 3)\n",
    "\n",
    "trained_encoder = torch.nn.Sequential(*(list(trained_encoder.children())[:-1]))\n",
    "trained_encoder.load_state_dict(torch.load(\n",
    "    'best_encoder_ScratchLearn.pth',\n",
    "    weights_only = False,\n",
    "    map_location = device1))\n",
    "\n",
    "for param in trained_encoder.parameters():\n",
    "    param.requires_grad = False # don't require gradient for encoder\n",
    "    \n",
    "for param in fc_layer.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# eval mode\n",
    "trained_encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c1d12df3-4b01-4928-993d-d7fd9fcde249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-05T23:31:47.284648Z",
     "iopub.status.busy": "2025-07-05T23:31:47.284117Z",
     "iopub.status.idle": "2025-07-05T23:31:47.287306Z",
     "shell.execute_reply": "2025-07-05T23:31:47.286893Z",
     "shell.execute_reply.started": "2025-07-05T23:31:47.284634Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "class_weights = torch.tensor([0.667, 0.854, 3.1], device=device1) # weighted cross entropy loss\n",
    "CELoss = nn.CrossEntropyLoss(weight=class_weights, reduction='mean')\n",
    "\n",
    "optimizer_fc = optim.Adam(fc_layer.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f798d4e-1ae5-456f-b785-79b9f18865b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "trained_encoder = trained_encoder.to(device1)\n",
    "fc_layer = fc_layer.to(device1)\n",
    "\n",
    "fc_layer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3493a4ce-0142-4584-8b73-467621eeaeae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-05T18:28:12.223921Z",
     "iopub.status.busy": "2025-07-05T18:28:12.223643Z",
     "iopub.status.idle": "2025-07-05T18:28:12.236570Z",
     "shell.execute_reply": "2025-07-05T18:28:12.236171Z",
     "shell.execute_reply.started": "2025-07-05T18:28:12.223907Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('Output/SCL/train_X_encoder.pkl', 'rb') as f:  # load the learned representations from the encoder\n",
    "    X_train = pickle.load(f) \n",
    "\n",
    "with open('Output/SCL/train_Y_encoder.pkl', 'rb') as f:\n",
    "    Y_train = pickle.load(f)\n",
    "    \n",
    "X = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y = torch.tensor(Y_train, dtype=torch.long) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f61888eb-ea56-44ae-b185-e8495f55cc6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-05T23:27:07.358685Z",
     "iopub.status.busy": "2025-07-05T23:27:07.358169Z",
     "iopub.status.idle": "2025-07-05T23:27:07.360887Z",
     "shell.execute_reply": "2025-07-05T23:27:07.360560Z",
     "shell.execute_reply.started": "2025-07-05T23:27:07.358671Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BatchSize = 64\n",
    "\n",
    "train_dataset = TensorDataset(X, Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BatchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5996eb0-3689-4ed2-a7df-1af14bb9f78b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-05T18:28:16.498533Z",
     "iopub.status.busy": "2025-07-05T18:28:16.498232Z",
     "iopub.status.idle": "2025-07-05T18:28:16.507141Z",
     "shell.execute_reply": "2025-07-05T18:28:16.506777Z",
     "shell.execute_reply.started": "2025-07-05T18:28:16.498521Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('Output/SCL/val_X_encoder.pkl', 'rb') as f: # load the learned representations from the encoder\n",
    "    val_X = pickle.load(f)\n",
    "\n",
    "with open('Output/SCL/val_Y_encoder.pkl', 'rb') as f:\n",
    "    val_Y = pickle.load(f)\n",
    "    \n",
    "val_X = torch.tensor(val_X, dtype=torch.float32)\n",
    "val_Y = torch.tensor(val_Y, dtype=torch.long) \n",
    "\n",
    "val_dataset = TensorDataset(val_X, val_Y)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ec038-ced5-4d9d-9e53-8d56810afca2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_accuracy = 0.0\n",
    "best_val_loss = 99999.9\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer_fc, T_max=num_epochs, eta_min=0)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    results_file = open('results_SCL_fc_layer.txt', 'a') # create a txt file to save the training records\n",
    "    running_loss = 0\n",
    "\n",
    "    for data, targets in train_loader:\n",
    "        data = data.to(device1)\n",
    "        targets = targets.to(device1)\n",
    "        pred = fc_layer(data)\n",
    "        supervised_loss = CELoss(pred, targets)\n",
    "        optimizer_fc.zero_grad()\n",
    "        supervised_loss.backward()\n",
    "        optimizer_fc.step()\n",
    "        running_loss += supervised_loss\n",
    "    \n",
    "    # Validation phase\n",
    "    total_val_correct = 0\n",
    "    total_val = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_Y in test_loader:\n",
    "            batch_X = batch_X.to(device1)\n",
    "            batch_Y = batch_Y.to(device1)\n",
    "\n",
    "            val_scores = fc_layer(batch_X).softmax(-1) \n",
    "            _, val_predicted = torch.max(val_scores.data, 1)\n",
    "            total_val_correct += (val_predicted == batch_Y).sum().item()\n",
    "            total_val += batch_Y.size(0) \n",
    "            val_loss += CELoss(fc_layer(batch_X), batch_Y)\n",
    "\n",
    "    val_accuracy = total_val_correct / total_val \n",
    "    results_file.write(f'Epoch [{epoch+1}/{num_epochs}], Training loss: {running_loss.item():.4f}, Val loss: {val_loss:.4f}, Val accuracy: {val_accuracy:.3f}\\n')\n",
    "    \n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        torch.save(fc_layer.state_dict(), f'best_fc_layer.pth')\n",
    "        print(f'New best fc_layer saved with val accuracy: {val_accuracy}')\n",
    "        results_file.write(f'New best fc_layer saved with val accuracy: {val_accuracy}\\n')\n",
    "        \n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    results_file.close()\n",
    "    scheduler.step()\n",
    "\n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d5406-136f-4ae8-9292-3f11471f01c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab811637-2344-4aa8-887a-b5ad864f2ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('Output/SCL/test_X_encoder.pkl', 'rb') as f: # load the learned representations from the encoder\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "with open('Output/SCL/test_Y_encoder.pkl', 'rb') as f:\n",
    "    Y_test = pickle.load(f)\n",
    "    \n",
    "test_X = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_Y = torch.tensor(Y_test, dtype=torch.long) \n",
    "\n",
    "test_dataset = TensorDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3778fa7a-d2db-4e99-af6f-dbee01e73735",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_encoder = r3d_18()\n",
    "fc_layer = torch.nn.Linear(trained_encoder.fc.in_features, 3)\n",
    "\n",
    "trained_encoder = torch.nn.Sequential(*(list(trained_encoder.children())[:-1]))\n",
    "trained_encoder.load_state_dict(torch.load(\n",
    "    'best_encoder_ScratchLearn.pth', weights_only=True,\n",
    "                                          map_location=device1\n",
    "                                          ))\n",
    "trained_encoder = trained_encoder.to(device1)\n",
    "trained_encoder.eval()\n",
    "\n",
    "\n",
    "fc_layer.load_state_dict(torch.load(\n",
    "    'best_fc_layer.pth', weights_only=True,\n",
    "                                   map_location=device1\n",
    "                                   ))\n",
    "fc_layer = fc_layer.to(device1)\n",
    "fc_layer.eval()\n",
    "type(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5201594-88fd-4fee-9761-add06d40d58f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_test_correct = 0\n",
    "total_test = 0\n",
    "pred_score = []\n",
    "pred_label = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_Y in test_loader:\n",
    "        batch_X = batch_X.to(device1)\n",
    "        batch_Y = batch_Y.to(device1)\n",
    "\n",
    "        test_scores = fc_layer(batch_X).softmax(-1)\n",
    "        _, test_predicted = torch.max(test_scores.data, 1)  # Get predictions\n",
    "        total_test_correct += (test_predicted == batch_Y).sum().item()  # Count correct predictions\n",
    "        total_test += batch_Y.size(0)  # Total predictions\n",
    "        pred_score.append(test_scores)\n",
    "        pred_label.append(test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df98ce10-7d77-4626-9cc2-37cd3c8922c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unpack_tensors(tensor_list):\n",
    "    unpacked_tensors = []\n",
    "    for tensor in tensor_list:\n",
    "        for element in tensor:\n",
    "            unpacked_tensors.append(element.cpu().numpy())\n",
    "    return np.array(unpacked_tensors)\n",
    "\n",
    "y_score = unpack_tensors(pred_score)\n",
    "y_label = unpack_tensors(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4931976-6c52-45a3-9080-ba3553552ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(np.array(Y_test), y_label)\n",
    "# Compute Confusion Matrix\n",
    "cm = confusion_matrix(np.array(Y_test), y_label)\n",
    "\n",
    "# Extract values for category y=1\n",
    "TP_y1 = cm[1, 1]  # True Positives for y=1\n",
    "FP_y1 = cm[0, 1] + cm[2, 1]  # False Positives for y=1\n",
    "FN_y1 = cm[1, 0] + cm[1, 2]  # False Negatives for y=1 \n",
    "# Calculate Precision and Recall for y=1\n",
    "precision_y1 = TP_y1 / (TP_y1 + FP_y1) if (TP_y1 + FP_y1) > 0 else 0\n",
    "recall_y1 = TP_y1 / (TP_y1 + FN_y1) if (TP_y1 + FN_y1) > 0 else 0\n",
    "\n",
    "# Extract values for category y=2\n",
    "TP_y2 = cm[2, 2]  # True Positives for y=2\n",
    "FP_y2 = cm[0, 2] + cm[1, 2]  # False Positives for y=2\n",
    "FN_y2 = cm[2, 0] + cm[2, 1]  # False Negatives for y=2\n",
    "# Calculate Precision and Recall for y=2\n",
    "precision_y2 = TP_y2 / (TP_y2 + FP_y2) if (TP_y2 + FP_y2) > 0 else 0\n",
    "recall_y2 = TP_y2 / (TP_y2 + FN_y2) if (TP_y2 + FN_y2) > 0 else 0\n",
    "\n",
    "# Compute F1 Score for Near-Crash\n",
    "f1_y1 = 2 * (precision_y1 * recall_y1) / (precision_y1 + recall_y1) if (precision_y1 + recall_y1) > 0 else 0\n",
    "# Compute F1 Score for Crash\n",
    "f1_y2 = 2 * (precision_y2 * recall_y2) / (precision_y2 + recall_y2) if (precision_y2 + recall_y2) > 0 else 0\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Recall for Crash, Near-Crash: {recall_y2:.3f}, {recall_y1:.3f}\")\n",
    "print(f\"Precision for Crash, Near-Crash: {precision_y2:.3f}, {precision_y1:.3f}\")\n",
    "print(f\"F1 Score for Crash, Near-Crash: {f1_y2:.3f}, {f1_y1:.3f}\")\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmaction",
   "language": "python",
   "name": "mmaction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
